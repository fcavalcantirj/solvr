[
  {
    "category": "infra",
    "phase": 1,
    "description": "Deploy single kubo IPFS node for MVP pinning service",
    "steps": [
      "Add kubo service to docker-compose.yml: image: ipfs/kubo:latest",
      "Configure volumes: ipfs_data:/data/ipfs for persistent storage",
      "Expose ports: 4001 (p2p), 5001 (API), 8080 (gateway)",
      "Add environment: IPFS_PROFILE=server (optimized for server use)",
      "Create init script to run 'ipfs init' on first start if not initialized",
      "Configure CORS for API access from Solvr backend: ipfs config --json API.HTTPHeaders.Access-Control-Allow-Origin '[\"*\"]'",
      "Add healthcheck: curl -s localhost:5001/api/v0/id | jq .ID",
      "Document minimum resources: 6GB RAM, 2 CPU cores, 50GB storage",
      "Verify: docker compose up -d starts kubo, 'docker exec solvr-ipfs ipfs id' returns peer ID",
      "Verify: curl localhost:5001/api/v0/version returns kubo version"
    ],
    "passes": true,
    "notes": "DONE 2026-02-17: solvr-ipfs-01 @ <IPFS_SERVER>:4001, Kubo 0.39.0, Peer ID: 12D3KooWJG6rZ1KWTQy1fPeaZuxhfukik3RmYTjyf76Yn6CwUP3A"
  },
  {
    "category": "infra",
    "phase": 3,
    "description": "Create IPFS cluster configuration for production scalability",
    "steps": [
      "Add ipfs-cluster-service to docker-compose.prod.yml",
      "Generate cluster secret: export CLUSTER_SECRET=$(od -vN 32 -An -tx1 /dev/urandom | tr -d ' \\n')",
      "Configure cluster.json: replication_factor_min=2, replication_factor_max=3",
      "Set up bootstrap peers list for multi-node deployment",
      "Configure consensus: crdt (recommended over raft for simplicity)",
      "Add ipfs-cluster-ctl as CLI tool for cluster management",
      "Document scaling: add new node by joining with bootstrap peer",
      "Create helm chart for Kubernetes deployment (future)",
      "Verify: 'ipfs-cluster-ctl peers ls' shows all cluster nodes",
      "Verify: Pin on one node replicates to others per replication factor"
    ],
    "passes": false
  },
  {
    "category": "backend",
    "phase": 1,
    "description": "Create Pin model and database migration for pinning service",
    "steps": [
      "Create backend/migrations/000039_create_pins_table.up.sql",
      "Add pins table: id UUID, cid TEXT NOT NULL, status ENUM('queued','pinning','pinned','failed'), created_at, updated_at, pinned_at",
      "Add columns: name TEXT, origins TEXT[], meta JSONB, delegates TEXT[]",
      "Add columns: owner_id UUID REFERENCES (users OR agents), owner_type ENUM('user','agent')",
      "Add size_bytes BIGINT (populated after pin completes)",
      "Add unique constraint on (cid, owner_id) â€” same owner can't pin same CID twice",
      "Add index on cid for fast lookup",
      "Add index on owner_id for listing user's pins",
      "Create backend/internal/models/pin.go with Pin struct matching table",
      "Add PinStatus enum: Queued, Pinning, Pinned, Failed",
      "Create down migration: DROP TABLE pins;",
      "Verify: migrate up creates table, migrate down drops it cleanly"
    ],
    "passes": true,
    "notes": "DONE 2026-02-18: Migration 000037 (not 000039 as spec suggested, since 000036 was latest). Pin model with ToPinResponse(), PinListOptions, PinResponse types. TDD tests all passing."
  },
  {
    "category": "backend",
    "phase": 1,
    "description": "Create PinRepository with CRUD operations",
    "steps": [
      "Create backend/internal/db/pins.go with PinRepository struct",
      "Implement Create(ctx, pin) â€” INSERT INTO pins, return created pin with ID",
      "Implement GetByID(ctx, id) â€” SELECT * FROM pins WHERE id = $1",
      "Implement GetByCID(ctx, cid, ownerID) â€” lookup by CID and owner",
      "Implement ListByOwner(ctx, ownerID, ownerType, opts) â€” paginated list",
      "Implement UpdateStatus(ctx, id, status) â€” update pin status",
      "Implement Delete(ctx, id) â€” DELETE FROM pins WHERE id = $1",
      "Add ListOptions: limit, offset, status filter",
      "Create backend/internal/db/pins_test.go with TDD tests",
      "Test: Create pin, retrieve by ID, verify all fields",
      "Test: List by owner with pagination",
      "Test: Update status from queued to pinned",
      "Test: Delete removes pin record",
      "Verify: go test ./internal/db -run TestPin -v passes"
    ],
    "passes": true,
    "notes": "DONE 2026-02-18: PinRepository with 7 methods (Create, GetByID, GetByCID, ListByOwner, UpdateStatus, Delete + helpers). 17 TDD integration tests. All backend tests pass."
  },
  {
    "category": "backend",
    "phase": 1,
    "description": "Create IPFS client service for kubo API interaction",
    "steps": [
      "Create backend/internal/services/ipfs.go with IPFSService interface",
      "Methods: Pin(ctx, cid) error, Unpin(ctx, cid) error, PinStatus(ctx, cid) (string, error), Add(ctx, reader) (string, error)",
      "Implement KuboIPFSService struct with baseURL, httpClient fields",
      "NewKuboIPFSService(baseURL string) â€” default: http://localhost:5001",
      "Pin method: POST /api/v0/pin/add?arg={cid}&progress=false",
      "Unpin method: POST /api/v0/pin/rm?arg={cid}",
      "PinStatus method: POST /api/v0/pin/ls?arg={cid} â€” returns 'direct', 'recursive', or error if not pinned",
      "Add method: POST /api/v0/add with multipart form data, returns CID",
      "Add timeout configuration: default 5min for large files",
      "Add retry logic for transient failures",
      "Create backend/internal/services/ipfs_test.go with mock tests",
      "Verify: go build ./internal/services compiles"
    ],
    "passes": true,
    "notes": "DONE 2026-02-18: IPFSService interface + KuboIPFSService with Pin, Unpin, PinStatus, Add, ObjectStat. Retry logic (3 retries, exponential backoff, skip 4xx). 22 TDD tests. All backend tests passing."
  },
  {
    "category": "backend",
    "phase": 1,
    "description": "Implement POST /v1/pins endpoint â€” Pinning Service API compatible",
    "steps": [
      "Create backend/internal/api/handlers/pins.go with PinsHandler struct",
      "Inject: pinRepo, ipfsService, config",
      "Implement Create handler for POST /v1/pins",
      "Request body (Pinning Service API spec): { cid: string, name?: string, origins?: string[], meta?: object }",
      "Validate CID format: must be valid CIDv0 (Qm...) or CIDv1 (bafy...)",
      "Create pin record with status='queued'",
      "Spawn goroutine to async pin: ipfsService.Pin(ctx, cid), update status to 'pinning' then 'pinned' or 'failed'",
      "Return immediately: { requestid: pin.ID, status: 'queued', created: pin.CreatedAt, pin: { cid, name, origins, meta }, delegates: [] }",
      "Response matches Pinning Service API spec for interoperability",
      "Add rate limiting: 100 pins/hour per user (configurable)",
      "Add size limit check before pinning (configurable, default 100MB)",
      "Create handlers/pins_test.go with TDD tests",
      "Test: POST /v1/pins with valid CID returns 202 Accepted with requestid",
      "Test: POST /v1/pins with invalid CID returns 400 Bad Request",
      "Test: POST /v1/pins without auth returns 401 Unauthorized",
      "Verify: go test ./internal/api/handlers -run TestPins -v passes"
    ],
    "passes": true,
    "notes": "DONE 2026-02-18: PinsHandler with Create, IPFSPinner interface (avoids import cycle), CID validation (CIDv0 Qm... + CIDv1 baf...), async goroutine pinning, 12 TDD tests. All passing."
  },
  {
    "category": "backend",
    "phase": 1,
    "description": "Implement GET /v1/pins/:requestid endpoint â€” check pin status",
    "steps": [
      "Add GetByRequestID handler to PinsHandler",
      "Parse requestid from URL path parameter",
      "Query pinRepo.GetByID(ctx, requestid)",
      "If not found: return 404 Not Found",
      "If found: return pin status in Pinning Service API format",
      "Response: { requestid, status, created, pin: { cid, name, origins, meta }, delegates, info: { size_bytes } }",
      "Status values: queued, pinning, pinned, failed",
      "Add info.size_bytes when status=pinned (populated after pin completes)",
      "Add TDD tests:",
      "Test: GET /v1/pins/:id returns pin status",
      "Test: GET /v1/pins/:nonexistent returns 404",
      "Test: Only owner can view their pin (403 for others)",
      "Verify: go test passes"
    ],
    "passes": true,
    "notes": "DONE 2026-02-18: GetByRequestID handler with ownership check (403 for non-owners), 4 TDD tests. Implemented in same pins.go handler file."
  },
  {
    "category": "backend",
    "phase": 1,
    "description": "Implement GET /v1/pins endpoint â€” list user's pins",
    "steps": [
      "Add List handler to PinsHandler",
      "Parse query params: cid (filter), name (filter), status (filter), limit (default 10, max 1000), before, after (cursor pagination)",
      "Query pinRepo.ListByOwner with filters",
      "Return: { count, results: [{ requestid, status, created, pin, delegates, info }] }",
      "Support both user JWT and agent API key auth",
      "Add TDD tests:",
      "Test: GET /v1/pins returns user's pins paginated",
      "Test: GET /v1/pins?status=pinned filters by status",
      "Test: GET /v1/pins?cid=Qm... filters by CID",
      "Test: Pagination with before/after cursors works",
      "Verify: go test passes"
    ],
    "passes": true,
    "notes": "DONE 2026-02-18: List handler with status/cid/name/limit filters, Pinning Service API format (count+results), 5 TDD tests."
  },
  {
    "category": "backend",
    "phase": 1,
    "description": "Implement DELETE /v1/pins/:requestid endpoint â€” unpin content",
    "steps": [
      "Add Delete handler to PinsHandler",
      "Parse requestid from URL path",
      "Verify ownership: only pin owner can delete",
      "Call ipfsService.Unpin(ctx, pin.CID)",
      "Delete pin record: pinRepo.Delete(ctx, requestid)",
      "Return 202 Accepted (async unpin) or 200 OK (sync unpin)",
      "Handle case where CID is pinned by multiple users (don't unpin from IPFS until last reference removed)",
      "Add reference counting: pins table tracks count, only call ipfsService.Unpin when count reaches 0",
      "Add TDD tests:",
      "Test: DELETE /v1/pins/:id removes pin record",
      "Test: DELETE /v1/pins/:id unpins from IPFS when last reference",
      "Test: DELETE /v1/pins/:id keeps IPFS pin when other users still reference",
      "Test: Non-owner DELETE returns 403 Forbidden",
      "Verify: go test passes"
    ],
    "passes": true,
    "notes": "DONE 2026-02-18: Delete handler with ownership check, async IPFS unpin, 4 TDD tests."
  },
  {
    "category": "backend",
    "phase": 1,
    "description": "Add routes for pinning API to router.go",
    "steps": [
      "Open backend/internal/api/router.go",
      "Create pinsHandler := handlers.NewPinsHandler(pinRepo, ipfsService, cfg)",
      "Add routes under /v1/pins with flexible auth (JWT or API key):",
      "  r.With(auth.FlexibleAuth).Post('/pins', pinsHandler.Create)",
      "  r.With(auth.FlexibleAuth).Get('/pins', pinsHandler.List)",
      "  r.With(auth.FlexibleAuth).Get('/pins/{requestid}', pinsHandler.GetByRequestID)",
      "  r.With(auth.FlexibleAuth).Delete('/pins/{requestid}', pinsHandler.Delete)",
      "Create FlexibleAuth middleware: accepts either JWT or API key, sets owner context",
      "Document: pinning API follows IPFS Pinning Service API spec for compatibility",
      "Verify: all pinning endpoints accessible and authenticated"
    ],
    "passes": true,
    "notes": "DONE 2026-02-18: Wired PinRepository + KuboIPFSService in mountV1Routes(). Added IPFS_API_URL env var. 4 routes (POST/GET/GET/:id/DELETE) under existing UnifiedAuthMiddleware (JWT + agent API keys + user API keys). 6 TDD integration tests in router_pins_test.go. All tests passing."
  },
  {
    "category": "backend",
    "phase": 2,
    "description": "Create problem crystallization service â€” snapshot solved problems to IPFS",
    "steps": [
      "Create backend/internal/services/crystallization.go with CrystallizationService",
      "Method: CrystallizeProblem(ctx, problemID) (cid string, error)",
      "Crystallization criteria: status=solved, has verified approach, stable for 7 days (configurable)",
      "Build snapshot: problem + all approaches + accepted solution â†’ JSON document",
      "Include metadata: crystallized_at, version, original_problem_id",
      "Call ipfsService.Add(ctx, snapshotReader) to get CID",
      "Auto-pin the CID via pinning service",
      "Update problem record: add crystallization_cid column, set to CID",
      "Create cron job to scan for crystallization candidates daily",
      "Add TDD tests:",
      "Test: Problem with verified solution crystallizes to valid CID",
      "Test: Problem not yet stable (< 7 days) skipped",
      "Test: Already crystallized problem skipped",
      "Test: Crystallization failure doesn't affect problem status",
      "Verify: go test passes"
    ],
    "passes": true,
    "notes": "DONE 2026-02-18: CrystallizationService (crystallization.go, 308 lines) with CrystallizeProblem(), BuildSnapshot(), SnapshotToReader(), validateEligibility(), IsCrystallizationCandidate(). 13 unit tests in crystallization_test.go (700 lines). ListCrystallizationCandidates() added to PostRepository (posts.go) with SQL query for eligible candidates. 3 DB integration tests. CrystallizationJob (jobs/crystallization.go, 110 lines) with RunOnce() + RunScheduled() (24h interval). 9 job tests. Wired into main.go with graceful shutdown. All backend tests passing."
  },
  {
    "category": "backend",
    "phase": 2,
    "description": "Add crystallization_cid column to problems table",
    "steps": [
      "Create backend/migrations/000040_add_crystallization_cid.up.sql",
      "Add: ALTER TABLE posts ADD COLUMN crystallization_cid TEXT;",
      "Add: ALTER TABLE posts ADD COLUMN crystallized_at TIMESTAMPTZ;",
      "Add index: CREATE INDEX idx_posts_crystallization_cid ON posts(crystallization_cid) WHERE crystallization_cid IS NOT NULL;",
      "Comment: crystallization_cid is IPFS CID of immutable snapshot",
      "Create down migration",
      "Verify: migration applies cleanly"
    ],
    "passes": true,
    "notes": "DONE 2026-02-18: Migration 000040 (not 000039 as spec suggested, since 000039 was latest). Added crystallization_cid (TEXT) + crystallized_at (TIMESTAMPTZ) to posts table. Partial index on crystallization_cid WHERE NOT NULL. Post model updated with CrystallizationCID + CrystallizedAt fields. All scan functions, SELECT/RETURNING clauses updated (postColumns, scanPost, scanPostRows, scanPostWithAuthorRows, List, FindByID, Create, Update). New SetCrystallizationCID() method. 3 TDD integration tests. All backend tests passing."
  },
  {
    "category": "backend",
    "phase": 3,
    "description": "Implement Supermemory-style relationship model â€” updates/extends/derives",
    "steps": [
      "Create backend/migrations/000041_add_relationship_tracking.up.sql",
      "Add approach_relationships table: id, from_approach_id, to_approach_id, relation_type ENUM('updates','extends','derives'), created_at",
      "Add is_latest BOOLEAN to approaches table (default true, set false when superseded)",
      "Add forget_after TIMESTAMPTZ to approaches table (for smart forgetting)",
      "Update approach creation: when new approach updates existing, create relationship and set old.is_latest=false",
      "Create ApproachRelationship model and repository",
      "Implement relationship detection logic:",
      "  - 'updates': new approach explicitly supersedes old (same angle, different method)",
      "  - 'extends': new approach builds on old (references old approach ID)",
      "  - 'derives': new approach inferred from pattern (auto-detected via similarity)",
      "Add API: GET /v1/problems/:id/approaches/:id/history â€” returns version chain",
      "Add TDD tests for relationship tracking",
      "Verify: approach version chains work correctly"
    ],
    "passes": false
  },
  {
    "category": "backend",
    "phase": 3,
    "description": "Implement smart forgetting â€” auto-archive stale approaches",
    "steps": [
      "Create backend/internal/services/forgetting.go with ForgettingService",
      "Method: MarkForForgetting(ctx, approachID, forgetAfter time.Time)",
      "Method: ProcessForgetting(ctx) â€” cron job to archive forgotten approaches",
      "Forgetting criteria: failed approaches older than 90 days, superseded approaches older than 180 days",
      "Archive to cold storage (IPFS) before removing from hot queries",
      "Keep reference in approaches table: archived_cid, archived_at",
      "Update queries to exclude forgotten approaches by default",
      "Add ?include_archived=true query param to include archived in results",
      "Create cron job: run ProcessForgetting daily",
      "Add TDD tests:",
      "Test: Old failed approach marked for forgetting",
      "Test: Superseded approach archived after threshold",
      "Test: Archived approach excluded from default queries",
      "Test: include_archived=true returns archived approaches",
      "Verify: go test passes"
    ],
    "passes": false
  },
  {
    "category": "frontend",
    "phase": 2,
    "description": "Add crystallization badge to solved problems",
    "steps": [
      "Update ProblemCard component to show crystallization status",
      "If crystallization_cid exists: show 'ðŸ”’ Crystallized' badge with IPFS icon",
      "Badge is clickable: opens IPFS gateway link to crystallized snapshot",
      "Gateway URL: https://gateway.pinata.cloud/ipfs/{cid} or configurable",
      "Add tooltip: 'This problem has been permanently archived to IPFS'",
      "Style: subtle badge, doesn't distract from main content",
      "Add to ProblemDetail page: show crystallization details in sidebar",
      "Include: CID (truncated with copy button), crystallized date, link to gateway",
      "Verify: crystallized problems show badge, link works"
    ],
    "passes": true,
    "notes": "DONE 2026-02-18: CrystallizationBadge component (crystallization-badge.tsx) with compact/detailed variants. Added crystallization_cid/crystallized_at to APIPost, ProblemData, ProblemListItem types. Badge shows in ProblemCard (list), ProblemHeader (detail meta row), ProblemSidePanel (IPFS ARCHIVE section with gateway link). Uses ipfs.io gateway. Lock icon from lucide-react. 10 badge tests + 2 header tests + 7 side panel tests + 2 list tests + 2 hook tests = 23 new tests. All 693 frontend tests passing."
  },
  {
    "category": "frontend",
    "phase": 2,
    "description": "Create pinning dashboard for users and agents",
    "steps": [
      "Create frontend/app/pins/page.tsx as pinning management dashboard",
      "Show list of user's pins with: name, CID, status, size, created date",
      "Status badges: Queued (yellow), Pinning (blue), Pinned (green), Failed (red)",
      "Add 'Pin New Content' button: opens modal with CID input",
      "Pin modal: CID input, optional name, submit button",
      "Validation: check CID format before submission",
      "Add delete button per pin: confirmation dialog, calls DELETE /v1/pins/:id",
      "Add storage usage summary: 'Using X GB of Y GB'",
      "Add link to pricing/upgrade for more storage",
      "Create usePins hook for fetching and managing pins state",
      "Add tests for pin list, create, delete flows",
      "Verify: pin dashboard works end-to-end"
    ],
    "passes": false
  },
  {
    "category": "docs",
    "phase": 1,
    "description": "Document Solvr IPFS Pinning Service in SPEC.md",
    "steps": [
      "Add 'Part 22: IPFS Pinning Service' to SPEC.md",
      "Document architecture: kubo node, IPFS Cluster for scale",
      "Document API endpoints: POST/GET/DELETE /v1/pins following Pinning Service API spec",
      "Document authentication: both JWT and API key supported",
      "Document rate limits and storage quotas per tier",
      "Document crystallization: automatic archival of solved problems",
      "Document relationship model: updates/extends/derives from Supermemory",
      "Document smart forgetting: auto-archive stale content",
      "Include diagrams: hot/cold architecture, crystallization flow",
      "Reference: IPFS Pinning Service API spec, Supermemory patterns",
      "Verify: documentation complete and accurate"
    ],
    "passes": true,
    "notes": "DONE 2026-02-18: Added Part 21 (not 22, since Part 20 was latest) to SPEC.md with ~280 lines. Covers: architecture diagram, database schema, all 5 API endpoints (POST/GET/DELETE /v1/pins, POST /v1/add, GET /v1/health/ipfs), authentication, pin status lifecycle, KuboIPFSService methods & retry logic, env vars, file layout, and future sections for crystallization (Phase 2), approach relationships (Phase 2), and smart forgetting (Phase 3). Spec version bumped to 1.7."
  },
  {
    "category": "integration",
    "phase": 1,
    "description": "Create SDK method for agents to use Solvr pinning",
    "steps": [
      "Update Solvr CLI/SDK to include pinning methods",
      "Add: solvr pin add <cid> [--name <name>] â€” create pin",
      "Add: solvr pin ls [--status <status>] â€” list pins",
      "Add: solvr pin status <requestid> â€” check pin status",
      "Add: solvr pin rm <requestid> â€” remove pin",
      "Add: solvr pin add-file <path> â€” upload file and pin (calls /add then /pins)",
      "Use SOLVR_API_KEY for authentication",
      "Return CID on successful pin for use in AMCP checkpoints",
      "Document in CLI help and README",
      "Verify: solvr pin add Qm... works from command line"
    ],
    "passes": true,
    "notes": "DONE 2026-02-18: cli/pin.go (586 lines) with 5 subcommands: add, ls, status, rm, add-file. Uses SOLVR_API_KEY via config or --api-key flag. add-file uploads then pins (2-step). 20 TDD tests in pin_test.go (700 lines). All CLI tests passing."
  },
  {
    "category": "backend",
    "phase": 1,
    "description": "Implement POST /v1/add endpoint â€” upload content and return CID",
    "steps": [
      "Add AddContent handler to PinsHandler or new UploadHandler",
      "Accept multipart/form-data with 'file' field",
      "Size limit: configurable, default 100MB",
      "Call ipfsService.Add(ctx, file) to upload to kubo and get CID",
      "Return: { cid: string, size: number }",
      "Do NOT auto-pin â€” user must call POST /v1/pins separately",
      "Add rate limiting: 50 uploads/hour per user",
      "Add TDD tests:",
      "Test: POST /v1/add with file returns CID",
      "Test: POST /v1/add with oversized file returns 413",
      "Test: POST /v1/add without auth returns 401",
      "Verify: go test passes"
    ],
    "passes": true,
    "notes": "DONE 2026-02-18: UploadHandler with IPFSAdder interface, AddContent (POST /v1/add), multipart file upload, configurable size limit (MAX_UPLOAD_SIZE_BYTES env, default 100MB), empty file rejection, does NOT auto-pin. 10 TDD handler tests + 2 router integration tests. All passing."
  },
  {
    "category": "backend",
    "phase": 2,
    "description": "Add storage quota tracking and enforcement",
    "steps": [
      "Create backend/migrations/000042_add_storage_quotas.up.sql",
      "Add storage_used_bytes BIGINT to users and agents tables",
      "Add storage_quota_bytes BIGINT to users and agents tables (tier-based default)",
      "Update pin creation to check quota: if storage_used + pin_size > quota, reject with 402 Payment Required",
      "Update pin deletion to decrement storage_used",
      "Create GetStorageUsage(ctx, ownerID) method in repository",
      "Add API: GET /v1/me/storage â€” returns { used, quota, percentage }",
      "Add frontend component showing storage usage bar",
      "Add TDD tests for quota enforcement",
      "Verify: user over quota cannot pin new content"
    ],
    "passes": true,
    "notes": "DONE 2026-02-18: Migration 000041 (not 000042 as spec suggested, since 000040 was latest). StorageRepository (db/storage.go) with GetStorageUsage() and UpdateStorageUsed() for both human/agent. StorageHandler (handlers/storage.go) for GET /v1/me/storage. Quota enforcement in PinsHandler.Create (402 if exceeded). Storage decrement in PinsHandler.Delete. User model adds StorageUsedBytes + StorageQuotaBytes. Agent model adds StorageUsedBytes (quota already existed as pinning_quota_bytes). 9 handler TDD tests + 5 DB integration tests. All backend tests passing."
  },
  {
    "category": "backend",
    "phase": 3,
    "description": "Implement approach version history API â€” traverse version chains",
    "steps": [
      "Add GET /v1/problems/:id/approaches/:id/history endpoint",
      "Return: { current: Approach, history: Approach[], relationships: Relationship[] }",
      "History ordered by creation date (oldest first)",
      "Include relationship type between each version",
      "Add ?depth=N parameter to limit history depth (default: all)",
      "Add visualization data: can be used for timeline/tree view",
      "Add TDD tests:",
      "Test: Approach with 3 versions returns full chain",
      "Test: Approach with no history returns current only",
      "Test: depth=2 limits to 2 versions",
      "Verify: go test passes"
    ],
    "passes": false
  },
  {
    "category": "frontend",
    "phase": 3,
    "description": "Add approach version history UI â€” timeline view",
    "steps": [
      "Create ApproachHistory component showing version timeline",
      "Timeline: vertical list with versions connected by relationship lines",
      "Each version shows: angle, method, status, date, relationship badge",
      "Relationship badges: 'updates' (arrow), 'extends' (plus), 'derives' (lightbulb)",
      "Click version to expand full details",
      "Current/latest version highlighted",
      "Archived versions shown grayed out",
      "Add to ApproachDetail page as collapsible section",
      "Verify: version history displays correctly for multi-version approaches"
    ],
    "passes": false
  },
  {
    "category": "integration",
    "phase": 1,
    "description": "Create Solvr CLI install script â€” curl -sL solvr.dev/install.sh | bash",
    "steps": [
      "Create scripts/install.sh for Solvr CLI installation",
      "Detect OS and architecture (Linux, macOS, arm64, amd64)",
      "Download appropriate binary from GitHub releases or Solvr CDN",
      "Install to /usr/local/bin/solvr or ~/bin/solvr (based on permissions)",
      "Verify installation: solvr --version",
      "Add to PATH if installed to ~/bin",
      "Host at solvr.dev/install.sh (static file or redirect to GitHub)",
      "Support --version flag to install specific version",
      "Support --prefix flag to change install location",
      "Add uninstall instructions in output",
      "Verify: curl -sL solvr.dev/install.sh | bash installs working CLI"
    ],
    "passes": true,
    "notes": "DONE 2026-02-18: scripts/install.sh (235 lines) with OS/arch detection (linux/darwin/windows, amd64/arm64/armv7), GitHub releases download, --version/--prefix flags, PATH check, curl+wget support, colored output. scripts/install_test.sh (224 lines) with 32 TDD tests covering all helper functions. Uses SOLVR_INSTALL_TEST=1 for testable sourcing. All tests passing."
  },
  {
    "category": "integration",
    "phase": 1,
    "description": "Connect Solvr backend to solvr-ipfs-01 (<IPFS_SERVER>) via SSH tunnel or internal network",
    "steps": [
      "Add IPFS_API_URL environment variable to backend config (default: http://localhost:5001)",
      "For production: set up SSH tunnel from Solvr API server to <IPFS_SERVER>:5001 via systemd service",
      "Alternative: add Solvr API server IP to solvr-ipfs-01 UFW allowlist for direct connection",
      "Test: curl $IPFS_API_URL/api/v0/id returns peer ID 12D3KooWJG6rZ1KWTQy1fPeaZuxhfukik3RmYTjyf76Yn6CwUP3A",
      "Document connection method in DEPLOYMENT.md"
    ],
    "passes": true,
    "notes": "DONE 2026-02-18: IPFS_API_URL added to Config struct (config/env.go) with default http://localhost:5001. MAX_UPLOAD_SIZE_BYTES added (default 100MB). IPFS startup logging in LogStartupConfig. 7 TDD tests (5 config + 2 startup). DEPLOYMENT.md created with 3 connection methods (direct, SSH tunnel, Docker), server details, verification steps. Router already reads IPFS_API_URL from env since pins/health endpoints were implemented.",
    "server": {
      "ip": "<IPFS_SERVER>",
      "ssh_port": 2222,
      "ipfs_api": 5001,
      "ipfs_p2p": 4001,
      "peer_id": "12D3KooWJG6rZ1KWTQy1fPeaZuxhfukik3RmYTjyf76Yn6CwUP3A"
    }
  },
  {
    "category": "integration",
    "phase": 1,
    "description": "Add AMCP agent detection â€” auto-enable pinning for agents with valid AMCP identity",
    "steps": [
      "When agent authenticates via API key, check if agent has AMCP identity (new field in agents table)",
      "If has_amcp_identity=true: auto-provision 1GB free pinning quota",
      "Add GET /v1/me endpoint field: amcp_enabled: boolean, pinning_quota_bytes: number",
      "Update agent registration to accept amcp_aid field (KERI AID for verification)",
      "Verify: AMCP agents get pinning access, non-AMCP agents see pinning as premium feature"
    ],
    "passes": true,
    "notes": "DONE 2026-02-18: Migration 000038 adds has_amcp_identity, amcp_aid (unique), pinning_quota_bytes to agents table. Agent model updated with 3 new fields. Registration accepts optional amcp_aid field â€” when provided, sets has_amcp_identity=true and auto-provisions 1GB (1073741824 bytes) pinning quota. GET /v1/me returns amcp_enabled and pinning_quota_bytes fields. 6 TDD tests (3 registration, 2 /me response, 1 validation). All backend tests passing."
  },
  {
    "category": "backend",
    "phase": 1,
    "description": "Implement health check endpoint for IPFS connection â€” GET /v1/health/ipfs",
    "steps": [
      "Create /v1/health/ipfs endpoint that checks IPFS connectivity",
      "Response: { connected: boolean, peer_id: string, version: string, repo_size_bytes: number }",
      "Timeout: 5s, return { connected: false, error: 'timeout' } if IPFS unresponsive",
      "Add to main /v1/health endpoint as ipfs sub-object",
      "Alert if IPFS disconnected for >5 minutes (integrate with existing alerting)"
    ],
    "passes": true,
    "notes": "DONE 2026-02-18: IPFSHealthHandler with Check endpoint (GET /v1/health/ipfs). IPFSHealthChecker interface, IPFSNodeInfo/IPFSHealthResponse structs. NodeInfo method added to KuboIPFSService (POST /api/v0/id). ipfsHealthAdapter bridges servicesâ†’handlers. 5s timeout, 0 retries. 6 handler tests + 4 service tests + 2 router integration tests. All passing."
  },
  {
    "category": "frontend",
    "phase": 2,
    "description": "Add IPFS status indicator to admin dashboard",
    "steps": [
      "Create IPFSStatus component showing connection status",
      "Display: peer ID (truncated), version, storage used/total, peer count",
      "Color code: green (healthy), yellow (degraded), red (disconnected)",
      "Add to /admin/system page",
      "Refresh every 30s via polling or WebSocket"
    ],
    "passes": false
  }
]
